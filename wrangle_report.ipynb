{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 0,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# <center> Report on The Process of Wrangling WeRateDogs Datasets </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is generally known, the Process of wrangling a data or datasets involves a combination of skill and know-how, in order to attempt to achieve to get a clean data to use for analysis. In this report, I explain the process of gathering and assessing WeRateDogs dataset from three different source using different methods.\n",
    "\n",
    "WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog. WeRateDogs has over 4 million followers and has received international media coverage. The dog ratings always have a denominator of 10 and the numerators is almost always greater than 10. Why? Because \"they're good dogs Brent!\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing The Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any wrangling process can be made, one needs to import python libraries that make working in Jupyter Notebook easier and smooth. Different libraries are sourced and combined to allow for accurate and efficient analysis. Before a library or libraries can be imported and used in Jupyter Notebook, it must first the installed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Gathering Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three datasets gathered for this project:\n",
    "1. A CSV file named twitter-archive-enhanced.csv, read with the regular pandas function. The file contains 2356 rows and 17 columns.\n",
    "2. A TSV file named image_predictions.tsv, was read directly from it url source using the pandas 'with open()' method. It has 2075 rows and 12 columns.\n",
    "3. A JSON file named tweet_json.txt, which was read also with the 'with open()' method as shown below. Its worthy of note that a Twitter API could also be used to gather this particular data. This dataset contains 2354 rows and 3 columns, as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My data assessment process involved the use of visual and programmatic method in discovering the issues of the datasets. Visual assessment involved exploring the dataset in a spreedsheet or using pandas methods to discover underlying messiness or untidiness in the dataset while Programmatic assessment, on the other hand, was done using pandas methods.\n",
    "\n",
    "However, due to the rigor of assessing datasets, I restricted the issues detected in this project to nine (9) quality issues and three (3) tidiness issue, using both visual and programmatic assessment.\n",
    "\n",
    "Also, I ensured I worked on copies of the datasets so as to preserve the original datasets in read into memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 7,
        "hidden": false,
        "row": 40,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "For this project, I employed a three-stage method The method used for data cleaning are:\n",
    "1. Define \n",
    "2. Code\n",
    "3. Test\n",
    "\n",
    "The Define stage focuses on how the overview of the issue and how I plan to solve it. The Code stage is where I actually write the python codes to resolve the issue. The Test stage is where I visualize my solution, to confirm that the issue has been resolved.\n",
    "\n",
    "In this section, I cleaned all of the issues documented while assessing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging and Storing Data\n",
    "The clean datasets were then merge into one final dataset that has 1917 rows and 13 columns. The final dataset was then stored in a master dataframe called twitter_archive_master.csv with utf-8 encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WeRateDogs datasets require ample time to wrangle and fully optimize, therefore, some consider it a difficult dataset.\n",
    "It is important to be versatile and open to every dataset, as the wrangling process is not one-size-fit-all. However, at all times, fundamental understaning will always work; no matter the given dataset."
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
